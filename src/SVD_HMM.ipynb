{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Requirement\" data-toc-modified-id=\"Requirement-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Requirement</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Hyperparameters\" data-toc-modified-id=\"Hyperparameters-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hyperparameters</a></span></li><li><span><a href=\"#Split-Dataset\" data-toc-modified-id=\"Split-Dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Split Dataset</a></span></li><li><span><a href=\"#Pre-Processing\" data-toc-modified-id=\"Pre-Processing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pre-Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-Blocks-For-Train\" data-toc-modified-id=\"Split-Blocks-For-Train-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Split Blocks For Train</a></span></li><li><span><a href=\"#Split-Blocks-For-Test\" data-toc-modified-id=\"Split-Blocks-For-Test-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Split Blocks For Test</a></span></li><li><span><a href=\"#Block-to-Sequence\" data-toc-modified-id=\"Block-to-Sequence-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Block to Sequence</a></span></li><li><span><a href=\"#Get-Trainig-Sequence\" data-toc-modified-id=\"Get-Trainig-Sequence-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Get Trainig Sequence</a></span></li><li><span><a href=\"#Get-Test-Sequence\" data-toc-modified-id=\"Get-Test-Sequence-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Get Test Sequence</a></span></li></ul></li><li><span><a href=\"#Hidden-Markov-Model\" data-toc-modified-id=\"Hidden-Markov-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Hidden Markov Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Initialize-Model\" data-toc-modified-id=\"Initialize-Model-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Initialize Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Test</a></span></li><li><span><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Evaluate</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement\n",
    "+ Python 3.7\n",
    "+ numpy 数据科学计算库 1.17.2\n",
    "+ matplotlib 画图库 3.1.1\n",
    "+ sklearn 数据科学处理库 0.22\n",
    "+ hmmlearn 隐马尔可夫模型库 0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hmmlearn import hmm\n",
    "\n",
    "from fetch_ORL_people import fetch_ORL_people\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "读取ORL数据集，数据集中共40个人脸，每个人10张图片，共计400张图片，存入`faces`\n",
    "`faces`具有以下属性：\n",
    "+ `data`: (400,)\n",
    "+ `images`: (400,56,46) 表示400张56X46的图片\n",
    "+ `target`: (400,) 400张图片对应的人，即标签，用0-39的数字表示\n",
    "+ `target_names`: (40,) 表示0-39每个数字对应的人名\n",
    "\n",
    "在加载数据集后已经做好了如下预处理：\n",
    "+ 将原来(112,92)大小的照片缩放为(56,46)大小\n",
    "+ 将原图片通过一个(3,3)的最小值滤波器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'images', 'target', 'target_names'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces = fetch_ORL_people('../Data')\n",
    "faces.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "+ `coeff`：量化范围\n",
    "+ `eps`：一个微小常数，防止除零错误\n",
    "+ `n_state`：隐藏状态数\n",
    "+ `n_obs`：观测状态数\n",
    "+ `n_person`：人脸类别数\n",
    "+ `random_split`：True 则随机划分，否则（默认）按原论文划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = np.array([18., 10., 7.])\n",
    "eps = 1e-6\n",
    "n_state = 7\n",
    "n_obs = 1260\n",
    "n_person = 40\n",
    "random_split = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "两种划分方法\n",
    "+ 随机层次划分，训练集和测试集各50%\n",
    "+ 按原论文划分，取每个人脸第1, 5, 6, 7, 10张图片作为训练集，其余作为测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_split:\n",
    "    idx_train, idx_test = train_test_split(np.arange(faces.images.shape[0]), test_size=0.5, stratify=faces.target, random_state=None)\n",
    "else:\n",
    "    idx_train = np.tile([0,4,5,7,9], n_person)\n",
    "    idx_test = np.tile([1,2,3,6,8], n_person)\n",
    "    for i in range(n_person):\n",
    "        idx_train[i*5:i*5+5] += i*10\n",
    "        idx_test[i*5:i*5+5] += i*10\n",
    "\n",
    "train_faces = faces.images[idx_train]\n",
    "y_train = faces.target[idx_train]\n",
    "test_faces = faces.images[idx_test]\n",
    "y_test = faces.target[idx_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "## Split Blocks For Train\n",
    "按照原论文描述，对训练集每张图片做如下处理：\n",
    "+ 将一张(56,46)大小的图片分割成52个有重叠的块\n",
    "+ 将52个块分别做SVD奇异值分解得到三个矩阵 $U,S,V$\n",
    "+ 取$U$矩阵第一个元素，$S$矩阵第一第二个元素，一共三个数作为该块的一个表示，即\n",
    "$block_i=[U(0,0),S(0),S(1)]$\n",
    "+ 保存每个块中，三个数的最大值可最小值，方便后面做归一量化（**Quantize**）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_block_cell_for_train(faces, n_blocks=52):\n",
    "    n_faces = faces.shape[0]\n",
    "    max_coeffs = np.array([-np.inf, -np.inf, -np.inf])\n",
    "    min_coeffs = np.array([np.inf, 0, 0])\n",
    "    block_cell = np.zeros(shape=(n_faces, n_blocks, 3))\n",
    "\n",
    "    for faces_index in range(n_faces):\n",
    "        img = faces[faces_index]\n",
    "        for block_index in range(n_blocks):\n",
    "            block = img[block_index:block_index + 5]\n",
    "            U, S, V = np.linalg.svd(block)\n",
    "            block_coeffs = np.array([U[0,0], S[0], S[1]])\n",
    "            min_coeffs = np.minimum(block_coeffs, min_coeffs)\n",
    "            max_coeffs = np.maximum(block_coeffs, max_coeffs)\n",
    "            block_cell[faces_index, block_index] = block_coeffs\n",
    "            \n",
    "    return min_coeffs, max_coeffs, block_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Blocks For Test\n",
    "利用训练集获得的信息：\n",
    "+ min_coeffs\n",
    "+ max_coeffs\n",
    "+ delta\n",
    "\n",
    "对测试集的图片进行类似的处理：\n",
    "+ 将一张(56,46)大小的图片分割成52个有重叠的块\n",
    "    + $52=\\frac{(H-L)}{L-p}$，其中$H$是图片的高度(56)，$L$是块的高度(5)，$P$是块之间重叠的长度(4)\n",
    "+ 将52个块分别做SVD奇异值分解得到三个矩阵 $U,S,V$\n",
    "+ 取$U$矩阵第一个元素，$S$矩阵第一第二个元素，一共三个数作为该块的一个表示，即\n",
    "$block_i=[U(0,0),S(0),S(1)]$\n",
    "+ 保证每个块的三个数位于训练集的最大值和最小值区间内，方便后面做归一量化（**Quantize**）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_block_cell_for_test(faces, min_coeffs, max_coeffs, n_blocks=52):\n",
    "    n_faces = faces.shape[0]\n",
    "    block_cell = np.zeros(shape=(n_faces, n_blocks, 3))\n",
    "    \n",
    "    for faces_index in range(n_faces):\n",
    "        img = faces[faces_index]\n",
    "        for block_index in range(n_blocks):\n",
    "            block = img[block_index:block_index + 5]\n",
    "            U, S, V = np.linalg.svd(block)\n",
    "            block_coeffs = np.array([U[0,0], S[0], S[1]])\n",
    "            block_coeffs = np.minimum(block_coeffs, max_coeffs)\n",
    "            block_coeffs = np.maximum(block_coeffs, min_coeffs)\n",
    "            block_cell[faces_index, block_index] = block_coeffs\n",
    "            \n",
    "    return block_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block to Sequence\n",
    "+ 将每个由三个数表示的块(block)变成一个整数表示，即将$block_i=[U(0,0),S(0),S(1)] \\rightarrow label \\in \\mathbb{Z}$\n",
    "+ 转化原理如下： 先将每个bolck中的三个数分别量化至 [18,10,7]，获得一个三位数，假设这个三位数为 $abc$\n",
    "    + 可以这样理解，a为18进制，b为10进制，c为7进制\n",
    "    + 将$abc$转化为一个整数，转化方法即为：$label = a \\times 10\\times 7 + b \\times 7 + c$\n",
    "    + 显然，$label \\in [0,1260)$，其中 $1260=18 \\times 10 \\times 7$\n",
    "+ 通过这种方法，将每张图片转化成为一个长度为52的序列表示，一共有200张图片，则有(200,52)的序列矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_to_seq(block_cell, min_coeffs, delta):\n",
    "    n_faces, n_blocks, _ = block_cell.shape\n",
    "    seq_matrix = np.zeros(shape=(n_faces, n_blocks))\n",
    "    for faces_index in range(n_faces):\n",
    "        for block_index in range(n_blocks):\n",
    "            block_coeffs = block_cell[faces_index, block_index]\n",
    "            Q_t = np.floor((block_coeffs - min_coeffs) / delta)\n",
    "            label = Q_t[0]*10*7 + Q_t[1]*7 + Q_t[2]\n",
    "            seq_matrix[faces_index, block_index] = label\n",
    "    return seq_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Trainig Sequence\n",
    "+ 从训练集获取三个信息\n",
    "    + min_coeffs\n",
    "    + max_coeffs\n",
    "    + delta\n",
    "+ 将训练集转化为序列矩阵(200,52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_coeffs, max_coeffs, train_block = split_block_cell_for_train(train_faces)\n",
    "delta = (max_coeffs - min_coeffs) / (coeff - eps)\n",
    "seq_train = block_to_seq(train_block, min_coeffs, delta)\n",
    "seq_train = seq_train.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Test Sequence\n",
    "+ 根据训练集获取的三个信息\n",
    "    + min_coeffs\n",
    "    + max_coeffs\n",
    "    + delta\n",
    "+ 将测试集转化为序列矩阵(200,52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_block = split_block_cell_for_test(test_faces, min_coeffs, max_coeffs)\n",
    "seq_test = block_to_seq(test_block, min_coeffs, delta)\n",
    "seq_test = seq_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model\n",
    "## Parameters\n",
    "按照原论文描述，定义马尔科夫模型的三个参数\n",
    "+ 初始概率分布`startprob`\n",
    "+ （隐）状态转移矩阵`transmat`\n",
    "+ 发射矩阵`emissionprob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始概率分布 (7,):\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      "状态转移矩阵 (7, 7):\n",
      " [[6.e-01 4.e-01 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      " [1.e-06 6.e-01 4.e-01 1.e-06 1.e-06 1.e-06 1.e-06]\n",
      " [1.e-06 1.e-06 6.e-01 4.e-01 1.e-06 1.e-06 1.e-06]\n",
      " [1.e-06 1.e-06 1.e-06 6.e-01 4.e-01 1.e-06 1.e-06]\n",
      " [1.e-06 1.e-06 1.e-06 1.e-06 6.e-01 4.e-01 1.e-06]\n",
      " [1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 6.e-01 4.e-01]\n",
      " [1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e+00]]\n",
      "发射矩阵 (7, 1260):\n",
      " [[0.001 0.001 0.001 ... 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 ... 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 ... 0.001 0.001 0.001]\n",
      " ...\n",
      " [0.001 0.001 0.001 ... 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 ... 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 ... 0.001 0.001 0.001]]\n"
     ]
    }
   ],
   "source": [
    "startprob = np.zeros(n_state)\n",
    "startprob[0] = 1.\n",
    "\n",
    "transmat = np.zeros([n_state, n_state]) + eps\n",
    "transmat[-1, -1] = 1.\n",
    "for i in range(n_state-1):\n",
    "    transmat[i, i] = 0.6\n",
    "    transmat[i, i+1] = 0.4\n",
    "\n",
    "transmat /= transmat.sum(1, keepdims=True)\n",
    "emissionprob = np.ones([n_state, n_obs]) / n_obs\n",
    "\n",
    "\n",
    "print(f'初始概率分布 {startprob.shape}:\\n {startprob}')\n",
    "print(f'状态转移矩阵 {transmat.shape}:\\n {transmat}')\n",
    "print(f'发射矩阵 {emissionprob.shape}:\\n {emissionprob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model\n",
    "+ 初始化模型的三个参数（初始概率，转移矩阵，发射矩阵），由于有四十个人（类别），因此需要40个隐马尔科夫模型，根据每个人的观测序列，更新优化各自的参数\n",
    "+ hmm.MultinomialHMM 类各个参数含义：\n",
    "    + `n_components`：隐状态个数\n",
    "    + `n_features`：观测状态的个数（不是观测序列的长度！）\n",
    "    + `tol`：模型训练时候的容忍度（决定模型何时收敛）\n",
    "    + `n_iter`：模型最多训练次数（如果达到该训练次数模型还未收敛则停止）\n",
    "    + `init_params`：是否需要模型（随机初始化）参数，可选`ste`分别代表初始状态分布，转移矩阵，发射矩阵，由于我们已经自定义了三个参数的初始化，因此这里只传入一个空字符串代表不进行随机初始化\n",
    "    + `startprob_`：初始概率分布，大小 (n_components,)\n",
    "    + `transmat_`： 转移矩阵，大小 (n_components, n_components)\n",
    "    + `emissionprob_`：发射矩阵，大小 (n_components, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [hmm.MultinomialHMM(n_components=n_state, tol=1e-2, n_iter=5, init_params='') for _ in range(n_person)]\n",
    "for model in models:\n",
    "    model.startprob_ = startprob\n",
    "    model.transmat_ = transmat\n",
    "    model.emissionprob_ = emissionprob\n",
    "    model.n_features = n_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "每个模型各自进行训练，即为每个人（类别）取它的5个观测序列，从而优化它对应的模型的三个参数（初始概率，转移矩阵，发射矩阵），训练时间仅为695ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 828 ms, sys: 0 ns, total: 828 ms\n",
      "Wall time: 823 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for person_idx, model in enumerate(models):\n",
    "    seq_idx = np.where(y_train==person_idx)[0]\n",
    "    obs = seq_train[seq_idx]\n",
    "    model.fit(obs.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "取测试集的200个观测序列，分别计算每个模型对该观测序列的似然概率（即计算这个序列由该模型生成的概率值），生成测试结果为一个(200,40)的矩阵，代表着每个序列对应的模型的概率，用时稍长，2.98s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.67 s, sys: 0 ns, total: 3.67 s\n",
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logprob = np.zeros((y_test.size, n_person))\n",
    "for seq_idx, obs in enumerate(seq_test):\n",
    "    for person_idx, model in enumerate(models):\n",
    "        logprob[seq_idx, person_idx] = model.score(np.atleast_2d(obs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "评测准确率，取概率值最大的模型对应的类别，就是该图片的类别，准确率同原论文一样达到了96.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别准确率 93.0%.\n"
     ]
    }
   ],
   "source": [
    "y_pred = logprob.argmax(1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'识别准确率 {accuracy*100}%.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "669.091px",
    "left": "273px",
    "top": "131.322px",
    "width": "310.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
